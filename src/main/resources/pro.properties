## spark application run cluster mode
spark.local=true

## Connection RDBMS
#jdbc.driver=com.mysql.jdbc.Driver
#jdbc.datasource.size=10
#jdbc.url=jdbc:mysql://10.28.0.83:3306/itm
#jdbc.user=tss
#jdbc.password=tss

## SPARK SQL TEST
#spark.sql.jdbc.url=jdbc:mysql://10.28.0.83:3306/itm?user=root&password=123456

## Kafka Cluster
metadata.broker.list=10.28.0.83:9092
kafka.topics=kafka-test
kafka.consumer.groupid=test-consumer-group
originTopic=test-topic-3
writeTopic=test-topic-1
ruleAlias=TOUDA
checkpointPath=./checkpoint/streaming-kafka-output-app
setSparkSeconds=500
setSparkAppName=kafka-output-streaming
setConFilePath=pro.properties


##解析规则的相关参数配置
#设置解析时的endpoint,配置解析规则的路径
tss.rule.api.endpoint=http://182.251.69.29:3000/api
tss.rule.api.context=/flume-rules




public.hadoop.userPrincipal=kafka_spark
public.hadoop.userKeytabpath=etc/kafka_spark.keytab
public.hadoop.krb5ConfPath=etc/krb5.conf
public.hadoop.ZkServerPrincipal=
